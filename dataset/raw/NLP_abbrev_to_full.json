{
    "SMT": "statistical machine translation",
    "CRF": "Conditional Random Field",
    "CRFs": "Conditional Random Fields",
    "WSD": "word sense disambiguation",
    "LP": "label propagation",
    "SVM": "support vector machine",
    "SVMs": "support vector machines",
    "RL": "reinforcement learning",
    "USR": "underspecified semantic representation",
    "USRs": "underspecified semantic representation",
    "EP": "Equivalent Pseudoword",
    "NER": "Named Entity Recognition",
    "HMM": "Hidden Markov model",
    "HMMs": "Hidden Markov models",
    "IE": "Information Extraction",
    "DOM": "Document Object Model",
    "QA": "question answering",
    "PFS": "progressive feature selection",
    "EM": "expectation maximization",
    "CE": "contrastive estimation",
    "TAT": "tree-to-string alignment template",
    "TATs": "tree-to-string alignment template",
    "ASR": "automatic speech recognition",
    "IR": "Information Retrieval",
    "POS": "part of speech",
    "NEs": "Named Entities",
    "DOP": "Data-oriented parsing",
    "Q/A": "question answering",
    "MT": "machine translation",
    "CODC": "Co-Occurrence Double Check",
    "PSM": "Phonetic Similarity Modeling",
    "PMT": "Punjabi Machine Transliteration",
    "SMS": "Short Messaging Service",
    "OOV": "Out-of-vocabulary",
    "SRL": "Semantic role labeling",
    "MMR": "Maximal Marginal Relevance",
    "CLTE": "cross-lingual textual entailment",
    "SR": "Semantic Role",
    "SPs": "Selectional Preferences",
    "SP": "Selectional Preference",
    "LDA": "Latent Dirichlet Allocation",
    "LSI": "Latent Semantic Indexing",
    "IMT": "Interactive Machine Translation",
    "MCMC": "Markov chain Monte Carlo",
    "CCG": "Combinatory Categorial Grammar",
    "CCGs": "Combinatory Categorial Grammars",
    "HPSG": "Head-driven phrase structure grammar",
    "HPSGs": "Head-driven phrase structure grammars",
    "LSA": "Latent Semantic Analysis",
    "FLM": "factored language modeling",
    "QCM": "Quantized Contour Modeling",
    "CLL": "conditional log-likelihood",
    "CLIR": "Cross-lingual information retrieval",
    "POMDP": "partially observable Markov decision process",
    "AMR": "Abstract Meaning Representation",
    "LaSA": "latent semantic association",
    "OOD": "out-of-distribution",
    "PosCal": "posterior calibrated",
    "MLMs": "Pretrained masked language models",
    "MLM": "Pretrained masked language model",
    "PLLs": "pseudo-log-likelihood scores",
    "PLL": "pseudo-log-likelihood score",
    "KG": "Knowledge graph",
    "KGs": "Knowledge graphs",
    "VAE": "Variational Autoencoder",
    "BN-VAE": "Batch Normalized-VAE",
    "CVAE": "conditional VAE",
    "MART": "Memory-Augmented Recurrent Transformer",
    "VLN": "vision-and-language navigation",
    "WASE": "Weakly Aligned Structured Embedding",
    "LMs": "language models",
    "SDS": "spoken dialogue system",
    "ST": "speech translation",
    "MAG": "Multimodal Adaptation Gate",
    "NLI": "natural language inference",
    "MRC": "machine reading comprehension",
    "BLI": "bilingual lexicon induction",
    "CLWE": "Cross-lingual word embeddings",
    "VVMA": "vector-vector-matrix architecture",
    "AL": "Active Learning",
    "CVT": "Cross-View Training",
    "HESM": "Hierarchical Evidence Set Modeling",
    "CFd": "class-aware feature self-distillation",
    "UDA": "unsupervised domain adaptation",
    "PrLMs": "pre-trained language models",
    "ERC": "emotion recognition in conversations",
    "RE": "relation extraction",
    "KD": "Knowledge distillation",
    "LH": "local histogram",
    "LHs": "local histograms",
    "AA": "authorship attribution",
    "KNN": "K-Nearest Neighbors",
    "KNNs": "K-Nearest Neighbors",
    "DCS": "dependency-based compositional semantics",
    "DoQ": "Distributions over Quantitative",
    "CTA": "Cognitive task analysis",
    "EFP": "Event factuality prediction",
    "MT-DNN": "Multi-Task Deep Neural Network",
    "DB": "database",
    "TABSA": "Targeted Aspect-based Sentiment Analysis",
    "ASP": "argumentation structure parsing",
    "COMET": "Commonsense Transformers",
    "LE": "Lexical entailment",
    "QG": "question generation",
    "IAL": "Introspective Alignment Layer",
    "CL": "curriculum learning",
    "DNNs": "Deep learning models",
    "CAGE": "Commonsense Auto-Generated Explanation",
    "IP": "input perturbation",
    "CLEAR": "Cross-Lingual Lexical Entailment Attract-Repel",
    "ARNs": "Anchor-Region Networks",
    "BAYESUM": "Bayesian summarization",
    "ACE": "Automatic Content Extraction",
    "KECG": "Knowledge Embedding model and Cross-Graph",
    "PBMT": "Pattern-Based Machine Translation",
    "ATRS": "automatic transcription reconstruction system",
    "NLP": "natural language processing",
    "NE": "named entity",
    "CFG": "context-free grammar",
    "ISs": "information states",
    "HMM-based": "Hidden Markov Model",
    "MBL": "memory-based classifier",
    "CART": "decision tree",
    "DLM": "dependency language model",
    "ECA": "embodied conversational agents",
    "MTGs": "Multitext Grammars",
    "FSAs": "Finite State Automata",
    "LFG": "Lexical-Functional Grammars",
    "HHMM": "hierarchical hidden Markov models",
    "SLU": "Spoken Language Understanding",
    "CIP": "cascaded induction process",
    "HBMs": "hidden backoff models",
    "AP": "Averaged Perceptron",
    "NM": "Navigation Map",
    "LM": "language model",
    "MLE": "maximum-likelihood estimation",
    "MEMM": "Maximum Entropy Markov Models",
    "DRT": "Discourse Representation Theory",
    "NMT": "neural machine translation",
    "DFGN": "Dynamically Fused Graph Network",
    "NLQA": "natural language based question answering",
    "NLMs": "Neural Language Modelling",
    "MTL": "Multi-task learning",
    "FSLR": "forward stagewise linear regression",
    "CLEC": "Chinese Learner Error Corpus",
    "WSJ": "Wall Street Journal",
    "EPs": "Equivalent Pseudowords",
    "CME": "conditional maximum entropy",
    "IDF": "inverse document frequency",
    "ISF": "inverse sentence frequency",
    "ITF": "inverse term frequency",
    "DUC": "Document Understanding Conference",
    "LCS": "Longest Common Subsequence",
    "pDPA": "pseudo DPA",
    "DF": "Dependency Forest",
    "PDG": "Preference Dependency Grammar",
    "TREC": "Text REtrieval Conference",
    "ISD": "Image Sense Discrimination",
    "TDL": "Typed Dynamic Logic",
    "ODIE": "On-demand Information Extraction",
    "ATB": "the Arabic Treebank",
    "AG": "Arabic Gigaword",
    "MSA": "Modern Standard Arabic",
    "WSM": "word support model",
    "STW": "syllable-to-word",
    "MSIME": "Microsoft Input Method Editor 2003",
    "EAT": "Edinburgh Association Thesaurus",
    "HAL": "Hyperspace Analog to Language",
    "BiTAM": "bilingual topical admixture",
    "HVR": "Haptic Voice Recognition",
    "AES": "Automated Essay Scoring",
    "FST": "Finite State Transducer",
    "PDTB": "the Penn Discourse TreeBank",
    "SITS": "Identity for Topic Segmentation",
    "PPD": "PKU's People's Daily",
    "RAP": "Relational Adaptive bootstraPping",
    "NEN": "named entity normalization",
    "CLMM": "cross-lingual mixture model",
    "cQAs": "community Question Answering services",
    "TP": "transformation patterns",
    "AFP": "Agence France Presse",
    "TC": "Text Categorization",
    "PM": "preference modeling",
    "ILP": "integer linear programming",
    "CCM": "constituent context model",
    "HPB": "hierarchical phrase-based",
    "PII": "personally identifiable information",
    "PEI": "personally embarrassing information",
    "NB": "Naive Bayes",
    "PASs": "trees and predicate-argument structures",
    "TIG": "tree insertion grammars",
    "TSG": "tree substitution grammars",
    "SSTH": "Semantic-Script Theory of Humor",
    "CEA": "Colloquial Egyptian Arabic",
    "TEI": "Text Encoding Initiative",
    "IMAM": "Information-theoretic Multi-view Adaptation Model",
    "SNA": "social network analysis",
    "GPC": "grapheme-phoneme conversion",
    "iSS": "incremental speech synthesis",
    "ML": "machine learning",
    "KM": "Kernel Methods",
    "SSL": "several semi-supervised learning",
    "ME": "Maximum Entropy",
    "CMM": "Conditional Markov Model",
    "SCFs": "acquisition of subcategorization frames",
    "GRs": "grammatical relations",
    "VSM": "vector space model",
    "ECG": "Career Guid- ance",
    "ESA": "Explicit Semantic Analysis",
    "RDWP": "Reader's Digest Word Power",
    "PBDGs": "transform Projective Bilexical Dependency Grammars",
    "CFGs": "Context-Free Grammars",
    "ASO": "Alternating Structure Optimization",
    "NPs": "noun phrases",
    "PBSMT": "Phrase-based Statistical Machine Translation",
    "MST": "Maximum Spanning Tree",
    "BF": "Bloom filter",
    "bLSA": "bilingual Latent Semantic Analysis",
    "NP": "noun phrase",
    "NMF": "Non-negative Matrix Factorization",
    "ECOC": "of error-correcting output codes",
    "MBR": "Minimum Bayes Risk",
    "PMI": "pointwise mutual information",
    "WER": "Word-Error-Rate",
    "PSCFG": "probabilistic synchronous context-free grammar",
    "HTER": "human-targeted translation edit rate",
    "FLP": "figurative language processing",
    "NELL": "Never-Ending Language Learner",
    "ITGs": "inversion transduction grammars",
    "NED": "Neutral Edge Direction",
    "HR": "handwriting recognition",
    "NUCLE": "NUS Corpus of Learner English",
    "KBP": "Knowledge Base Population",
    "KB": "knowledge base",
    "FHMMs": "factorial hidden Markov models",
    "CLC": "class-label correlation",
    "TAG": "tree adjoining grammars",
    "LbR": "Learning by Reading",
    "PCFG": "probabilistic context free grammars",
    "CCA": "Canonical Correlation Analysis",
    "LDC": "Linguistic Data Consortium",
    "BTSG": "Bayesian tree substitution grammars",
    "RGB": "Relation Guided Bootstrapping",
    "LWLM": "Latent Words Language Model",
    "DS": "distant supervision",
    "PSD": "preposition sense disambiguation",
    "LMDE": "Mixture of Discriminative Experts",
    "HTR": "handwritten text recognition",
    "SDG": "similarity-based decoding generation",
    "MA": "morphological analysis",
    "MDL": "Minimum Description Length",
    "MRW": "Markov Random Walk",
    "SFC": "Subject Field Codes",
    "IDSS": "identification of domain-specific senses",
    "UGC": "user-generated content",
    "SSA": "Sentiment Analysis",
    "MRL": "Morphologically-Rich Languages",
    "PA": "Passive-Aggressive",
    "HRL": "Hierarchical Reinforcement Learning",
    "SDP": "shortest-derivation parsing",
    "mWEs": "multiword expressions",
    "EULA": "End-User License Agreement",
    "ERP": "Event related potentials",
    "EEG": "electroencephalography",
    "BCI": "brain computer interfaces",
    "RSVP": "rapid serial visual presentation",
    "MEAD": "multi-document summarization system",
    "UIMA": "Unstructured Information Management Architecture",
    "LOP": "logarithmic opinion pool",
    "QBTE": "Question-Biased Term Extraction",
    "MEMs": "Maximum Entropy Models",
    "MAP": "Mean Average Precision",
    "LID": "language identification",
    "ISS": "International Space Station",
    "PSPL": "Position Specific Posterior Lattice",
    "TM": "transliteration model",
    "TFSGs": "typed feature structure grammars",
    "ERG": "English Resource Grammar",
    "LDD": "long distance dependency",
    "MEMT": "multiengine machine translation",
    "KPCA": "Kernel Principal Component Analysis",
    "LCFRS": "Linear Context-Free Rewriting Systems",
    "FLSA": "Feature Latent Semantic Analysis",
    "POSs": "part of speech",
    "BNC": "British National Corpus",
    "SPC": "Sinorama Parallel Corpus",
    "WFST": "weighted finite-state transducer",
    "SSR": "Structural Semantic Relatedness",
    "REG": "referring expression generation",
    "NAS": "non-aligned signatures",
    "BTKs": "propose Bilingual Tree Kernels",
    "ITG": "Inversion Transduction Grammar",
    "HL": "Hierarchical Learning",
    "SOT": "Sentiment Ontology Tree",
    "MLIGs": "multiset-valued linear indexed grammars",
    "cQA": "community Question Answering",
    "STSG": "synchronous tree-substitution grammar",
    "WoZ": "Wizard-of-Oz",
    "STAGs": "synchronous tree-adjoining grammars",
    "PCLSA": "Probabilistic Cross-Lingual Latent Semantic Analysis",
    "PLSA": "Probabilistic Latent Semantic Analysis",
    "PCFGs": "Probabilistic Context-Free Grammars",
    "AGs": "Adaptor Grammars",
    "DMV": "Model with Valence",
    "WCLs": "Word-Class Lattices",
    "PRF": "Pseudo-Relevance Feedback",
    "MBF": "Model Based Feedback",
    "MASC": "Manually Annotated Sub-Corpus",
    "NCD": "normalized compression distance",
    "VS": "verbal subject",
    "PR": "posterior regularization",
    "LSH": "Locality Sensitive Hash",
    "SCL": "structural correspondence learning",
    "JSCM": "joint source channel model",
    "HGMs": "hierarchical graphical models",
    "DA": "dialogue act",
    "LRT": "resources and tools",
    "NPCs": "demands between nonplayer characters",
    "RDF": "Resource Descriptor Format",
    "DM": "Dialogue Manger",
    "CICD": "Collective and Individual Cognition",
    "MF": "Mention Flags",
    "DST": "dialogue state tracking",
    "BoB": "BERT-over-BERT",
    "PTMs": "Although the pre-trained models",
    "MIN": "Modularized Interaction Network",
    "EAE": "event argument extraction",
    "BERD": "Bi-directional Entity-level Recurrent Decoder",
    "CRE": "continual relation extraction",
    "BTBA": "bidirectional Transformer based alignment",
    "LaSS": "learns Language Specific Sub-network",
    "MGNNS": "Graph Neural Networks with Sentiment-awareness",
    "ACOS": "Aspect-Category-Opinion-Sentiment",
    "MTLS": "Multiple TimeLine Summarization",
    "TLS": "Time-Line Summarization",
    "TaSc": "Task-Scaling",
    "IAIS": "Alignment on Intra-modal Self-attentions",
    "VCG": "Visual Commonsense Generation",
    "KCG": "Knowledge-based Commonsense Generation",
    "MHA": "multi-head attention",
    "CODA": "cascaded head-colliding attention",
    "COSY": "COunterfactual SYntax",
    "SCM": "Stereotype Content Model",
    "ToM": "theory of mind",
    "IAT": "Inverse Adversarial Training",
    "MMI": "maximum mutual information",
    "SciIE": "scientific information extraction",
    "SOTA": "state-of-the-art",
    "EL": "Entity linking",
    "IDG": "Integrated Directional Gradients",
    "DML": "deep metric learning",
    "GME": "Gradable Modal Expressions",
    "SUs": "sentence-like units",
    "FV": "fact verification",
    "DQN": "deep Q-learning network",
    "LRP": "Layerwise Relevance Propagation",
    "NLG": "Natural Language Generation",
    "MR": "meaning representation",
    "CSR": "advance commonsense reasoning",
    "MCP": "multilingual contrastive pretraining",
    "LRL": "low web-resource languages",
    "RPL": "Related Prominent Language",
    "AM": "Argument Mining",
    "AAC": "Alternative Communication",
    "RQE": "Recognizing Question Entailment",
    "NERC": "entity recognition and classification",
    "MECT": "Multi-metadata Embedding based Cross-Transformer",
    "DAG": "directed acyclic graph",
    "CARI": "present Context-Aware Rule Injection",
    "pJSD": "pointwise Jensen-Shannon Divergence",
    "IC": "instance-level curriculum",
    "DPR": "dropped pronoun recovery",
    "CDP": "conversational discourse parsing",
    "GCN": "Graph Convolutional Network",
    "SPDPR": "Structure Parsing-enhanced Dropped Pronoun Recovery",
    "KGE": "Knowledge Graph Embedding",
    "mBERT": "multi-lingual models, namely multi-lingual BERT",
    "WSLS": "Saliency speedup Local Search",
    "SoTA": "learning has yielded state-of-the-art",
    "NAT": "neural machine translation",
    "GLM": "Glancing Language Model",
    "GLAT": "Glancing Transformer",
    "PrLM": "pretrained language model",
    "HPO": "hyperparameter optimization methods",
    "XDTS": "cross-database context-dependent Text-to-SQL",
    "CLINE": "Learning with semantIc Negative Examples",
    "ExCAR": "enhanced explainable CAusal Reasoning framework",
    "CMNLN": "Conditional Markov Neural Logic Network",
    "DRM": "domain-regularized module",
    "NL": "natural language",
    "MSP": "Multi-stage Pre-training",
    "CMCL": "cross-modal contrastive learning",
    "MMIN": "Missing Modality Imagination Network",
    "SATE": "Stacked Acoustic-and-Textual Encoding",
    "MLR": "Multi-Level Ranking",
    "NCTTI": "Compound Type and Token Idiomaticity",
    "OC": "Ordinal Classification",
    "OQ": "Ordinal Quantification",
    "HIF": "Heterogeneous Information Fusion",
    "KAT": "Key Attribute Tree",
    "ED": "Event Detection",
    "UNMT": "unsupervised neural machine translation",
    "HSK": "hidden state knowledge",
    "LL": "Lifelong learning",
    "EnsLM": "ensemble language model",
    "CLO": "cross-level optimization",
    "CSC": "Chinese spelling correction",
    "PLOME": "Language model with Misspelled knowledgE",
    "SEQA": "SEmantic-based Question Answering method",
    "PLMs": "pre-trained language models",
    "ECE": "Emotion Cause Extraction",
    "KPA": "Key Point Analysis",
    "MTO": "Margin-based Token-level Objective",
    "MSO": "Margin-based Sentence-level Objective",
    "ESC": "Emotional Support Conversation",
    "NSD": "Novel Slot Detection",
    "PQA": "post question answer",
    "PQ": "post-question",
    "CQG": "conversational question generation",
    "ECI": "event causality identification",
    "MPC": "multi-party conversation",
    "CDRNN": "continuous-time deconvolutional regressive neural network",
    "NN": "neural network",
    "EBGCN": "Edge-enhanced Bayesian Graph Convolutional Network",
    "LDGN": "dual graph neural network",
    "BoW": "bag-of-words",
    "PDRMM": "POSIT-Deep Relevance Matching Model",
    "DRS": "discourse rhetorical structure",
    "CJPE": "Judgment Prediction and Explanation",
    "ODQA": "open-domain question answering",
    "GAR": "propose Generation-Augmented Retrieval",
    "VQA": "Visual Question Answering",
    "SAR": "select and rerank",
    "OCR": "optical character recognition",
    "GAT": "graph attention network",
    "AmbER": "Ambiguous Entity Retrieval",
    "EBR": "energy-based re-ranking",
    "GAN": "generative adversarial network",
    "FEAE": "Frame-aware Event Argument Extraction",
    "MoE": "Mixture-of-Experts",
    "CoRI": "collective Relation Integration",
    "CDC": "cross document entity coreference",
    "ASTE": "Aspect Sentiment Triplet Extraction",
    "ATE": "Aspect Term Extraction",
    "OTE": "Opinion Term Extraction",
    "GWLAN": "general word-level autocompletion",
    "ECR": "event coreference resolution",
    "LSIN": "Latent Structure Induction Network",
    "PETER": "PErsonalized Transformer for Explainable Recommendation",
    "CGEC": "Chinese Grammatical Error Correction",
    "TtT": "framework named Tail-to-Tail",
    "eSPD": "early sexual predator detection",
    "VLR": "Visual-Language Retrieval",
    "LLR": "Language-Language Retrieval",
    "HTC": "Hierarchical Text Classification",
    "STS": "semantic textual similarity",
    "AST": "Abstract Syntax Tree",
    "SSD": "Synchronous Semantic Decoding",
    "UID": "uniform information density",
    "SACE": "Sense Aware Context Exploitation",
    "FI": "Frame Identification",
    "KGFI": "Knowledge-Guided Frame Identification framework",
    "WE": "word embedding",
    "CTFN": "coupled-translation fusion network",
    "PLM": "pre-trained language models",
    "CdKD": "Cross-domain Knowledge Distillation",
    "DNE": "Dirichlet Neighborhood Ensemble",
    "DCVED": "de-confounded variational encoder-decoder",
    "NoIRs": "non-helpful rationales",
    "CQS": "Conversational Question Simplification",
    "RISE": "Reinforcement Iterative Sequence Editing",
    "IRT": "Iterative Reinforce Training",
    "DPS": "Programming based Sampling",
    "PGD": "prioritized gradient descent",
    "MSG": "Multi-source sequence generation",
    "WIST": "word-internal structure treebank",
    "CMN": "cross-modal memory networks",
    "MRA": "Multimodal Review Analysis",
    "MRHP": "Multimodal Review Helpfulness Prediction",
    "MCR": "Coherent Reasoning method",
    "SAD": "Shallow Aggressive Decoding",
    "GEC": "Grammatical Error Correction",
    "DCQG": "Difficulty-Controllable Question Generation",
    "NR": "Number Ranking",
    "NAG": "non-autoregressive generation",
    "POSPD": "POS-constrained Parallel Decoding",
    "RRG": "Related work Generator",
    "QFS": "query focused summarization",
    "xMoCo": "Cross Momentum Contrastive learning",
    "MMT": "multimodal machine translation",
    "MASN": "propose Motion-Appearance Synergistic Networks",
    "CHMM": "conditional hidden Markov model",
    "MIL": "multi-instance learning",
    "CIL": "contrastive instance learning",
    "NT": "negative training",
    "PRGC": "Relation and Global Correspondence",
    "MUCO": "Undefined Classes from Other-class",
    "EE": "Event extraction",
    "DEE": "Document-level event extraction",
    "ACD": "Aspect category detection",
    "APE": "Argument pair extraction",
    "KiS": "Keep it Simple",
    "DPPs": "determinantal point processes",
    "HDGCN": "high-order dynamic Chebyshev approximation",
    "ADC": "adversarial data collection",
    "KGQA": "Question Answering over KG",
    "MARS": "Model Augmented Relevance Score",
    "MSTGs": "material state transfer graphs",
    "PE": "post-editing",
    "TGMs": "text generation metrics",
    "KGC": "Knowledge Graph Completion",
    "MCLAS": "framework for Cross-Lingual Abstractive Summarization",
    "EER": "equal error rate",
    "FAR": "false acceptance rate",
    "IRR": "inter-rater reliability",
    "xRR": "cross-replication reliability",
    "APT": "Adversarial Paraphrasing Task",
    "WALS": "Atlas of Language Structures",
    "NLU": "Natural Language Understanding",
    "SLP": "Sign Language Processing",
    "OT": "optimal transport",
    "RAD": "Robustness to Augmented Data",
    "IRL": "Inverse Reinforcement Learning",
    "AANs": "average attention networks",
    "TISA": "translation-invariant self-attention",
    "COPA": "Choice of Plausible Alternatives",
    "EMG": "electromyography",
    "QE": "quality estimation",
    "MWEs": "monolingual word embeddings",
    "BWEs": "bilingual word embeddings",
    "MNMT": "multilingual neural machine translation",
    "MRR": "Mean Reciprocal Rank",
    "PRAL": "Pre-trainedRole Alternating Language model",
    "GCNs": "Graph Convolutional Networks",
    "ROPE": "Order Equivariant Positional Encoding",
    "TE": "Textual Entailment",
    "MIMO": "Multi-Input-Multi-Output",
    "kNN": "k-nearest-neighbor",
    "DCT": "Discrete Cosine Transform",
    "AC": "Adaptive Computation",
    "DCRAN": "Deep Contextualized Relation-Aware Network",
    "BMI": "bilingual mutual information",
    "TPEM": "task-oriented dialogue system with iterative network pruning, expanding, and masking",
    "CWS": "Chinese word segmentation",
    "BEL": "biomedical entity linking",
    "CWRs": "Contextual Word Representations",
    "mPLM": "multilingual pretrained language models",
    "TTE": "time to event",
    "QASF": "introduce QA-driven slot filling",
    "CKG": "Commonsense Knowledge Graphs",
    "mBART": "multilingual BART",
    "MNPP": "Masked Noun-Phrase Prediction",
    "REAG": "Rationale-Enriched Answer Generator",
    "MSPAN": "Multi-Scale Progressive Attention Network",
    "BPR": "Binary Passage Retriever",
    "BIO": "domains-CV and Bioinformatics",
    "GIFs": "graphics interchange formats",
    "CLTK": "Classical Language Toolkit",
    "ESRA": "Explainable Scientific Research Assistant",
    "IED": "Improvised Explosive Device",
    "CRSs": "conversational recommender systems",
    "LOA": "Logical Optimal Actions",
    "AEA": "Automated Essay Assessment",
    "PDF": "Portable Document Format",
    "PAWLS": "Annotation with Labels and Structure",
    "NLDB": "natural language database interface",
    "KBQA": "knowledge base question answering",
    "MEMD": "Maximum Entropy/Minimum Divergence",
    "MDPs": "Markov Decision Processes",
    "CB": "backward-looking center",
    "VT": "Veins Theory",
    "WSME": "Maximun Entropy Language Model",
    "CLLS": "constraint language for &#955;-structures",
    "SPN": "semantic perceptron net",
    "NFA": "Non-deterministic Finite-state Automata",
    "DFA": "Deterministic Finite-state Automata",
    "NNJM": "neural network joint model",
    "DNN": "deep neural network",
    "RCNN": "recursive convolutional neural network",
    "LSTM": "Long Short-Term Memory",
    "NRM": "Neural Responding Machine",
    "RNN": "recurrent neural networks",
    "LCH": "Leacock and Chodorow",
    "CNN": "convolutional neural network",
    "ASD": "autism spectrum disorder",
    "ADP": "augmented dependency path",
    "CNNs": "convolution neural networks",
    "SMRT": "Simulated Multiple Reference Training",
    "KTL": "Knowledge Triplet Learning",
    "ETC": "Extended Transformer Construction",
    "CPC": "Contrastive Predictive Coding",
    "DL": "deep learning",
    "MQM": "Multidimensional Quality Metric",
    "EALM": "Language Model converter",
    "TA": "topic assistant",
    "CoDIR": "Contrastive Distillation on Intermediate Representations",
    "KCN": "Knowledge Consolidation Network",
    "GRF": "Multi-Hop Reasoning Flow",
    "EMAP": "empirical multimodally-additive function projection",
    "MUTE": "Multi-Unit Transformer",
    "LAT": "local autoregressive translation",
    "CMLM": "conditional masked language model",
    "RC": "reading comprehension",
    "ViPT": "scale visual procedure telling",
    "LADA": "Additivity based Data Augmentation",
    "MHGRN": "named multi-hop graph relation network",
    "RRT": "Rounded Reparameterization Trick",
    "RV": "rumor verification",
    "OTS": "off-the-shelf",
    "CTRP": "Clinical Trial Result Prediction",
    "APSI": "Analogous Process Structure Induction",
    "SBERT": "Sentence BERT",
    "SAT": "Structure-Aware Transformer",
    "GAIN": "propose Graph Aggregation-and-Inference Network",
    "MG": "mention-level graph",
    "EG": "entity-level graph",
    "MAVEN": "MAssive eVENt detection dataset",
    "PCG": "pair-wise connectivity graph",
    "KPE": "Open-domain Keyphrase extraction",
    "BiST": "Bi-directional Spatio-Temporal Learning",
    "VRNN": "Variational Recurrent Neural Network",
    "CCN": "Cross Copy Networks",
    "MDST": "multidomain dialogue state tracking",
    "PIN": "Parallel Interactive Networks",
    "IB": "Information Bottleneck",
    "MAF": "Multimodal Alignment Framework",
    "MFM": "Masked Frame Modeling",
    "FOM": "Frame Order Modeling",
    "OIX": "Open-domain Information eXpression",
    "OIA": "Open Information Annotation",
    "STE": "straight-through estimator",
    "LT": "label transfer",
    "GS": "Gumbel sampling",
    "CLT": "cross-lingual transfer",
    "MGL": "meta graph learning",
    "XCOPA": "Cross-lingual Choice of Plausible Alternatives",
    "EDU": "elementary discourse units",
    "RU": "Roman Urdu",
    "HENIN": "HEterogeneous Neural Interaction Networks",
    "XLM": "cross-lingual pretraining model",
    "MSNN": "Modularized Syntactic Neural Network",
    "AMRs": "Abstract Meaning Representations",
    "LLL": "lifelong language learning",
    "HDP": "hierarchical Dirichlet process",
    "GE": "Graph embedding",
    "CREST": "Context Relevant Episodic State Truncation",
    "EMD": "Earth Mover Distance",
    "SA": "Slot Attention",
    "VN": "Value Normalization",
    "GDIN": "Graph Dimensional-Iteration Network",
    "SCT": "Story Cloze Test",
    "MFT": "Meta Fine-Tuning",
    "VFD": "visually-grounded first-person dialogue",
    "UGI": "unsupervised grammar induction",
    "MinTL": "Minimalist Transfer Learning",
    "VHDA": "Variational Hierarchical Dialog Autoencoder",
    "KDBTS": "Knowledge Distillation Based Training Strategy",
    "TTOS": "Two-Teacher One-Student learning framework",
    "ARTS": "Aspect Robustness Test Set",
    "DocRE": "document-level relation extraction",
    "TKBC": "Temporal Knowledge Base Completion",
    "IGL": "Iterative Grid Labeling",
    "HVAE": "Hierarchical Variational Auto-Encoder",
    "EPT": "Expression-Pointer Transformer",
    "MWPs": "math word problems",
    "UET": "Universal Expression Tree",
    "HMWP": "Math Word Problems dataset",
    "GNNs": "Graph Neural Networks",
    "GTM": "Graph Topic Model",
    "RGM": "enforced generative model",
    "FITB": "fill-in-the-blank",
    "DG": "derivation generation",
    "GD": "Gaussian-masked Directional",
    "OOS": "out-of-scope examples",
    "SIL": "Seeded Iterated Learning",
    "SSIL": "Supervised Seeded Iterated Learning",
    "VMASK": "variational word mask",
    "ALICE": "Active Learning with Contrastive Explanations",
    "RxR": "Room-Across-Room",
    "SSCR": "Self-Supervised Counterfactual Reasoning",
    "CTC": "cross-task consistency",
    "CWE": "Cross-lingual word embedding",
    "MWE": "Multi-Word Expressions",
    "XLMR": "XLM-RoBERTa",
    "MARC": "Multilingual Amazon Reviews Corpus",
    "MAE": "mean absolute error",
    "CF": "catastrophic forgetting",
    "NSP": "next sentence prediction",
    "GSim": "Simulated Dialogue",
    "SGD": "Schema-Guided Dialogue",
    "BLM": "Blank Language Model",
    "IGTs": "interlinear glossed texts",
    "EmoRL": "Supervision (EmoSup) and two Emotion-Reinforced",
    "BeeSL": "Biomedical Event Extraction as Sequence Labeling",
    "TDGs": "temporal dependency graphs",
    "UI": "user interface",
    "MACD": "Multimodal Aligned Contrastive Decoupled learning",
    "BITE": "Base-Inflection Encoding",
    "TeMP": "Temporal Message Passing",
    "CRQDA": "Controllable Rewriting based Question Data Augmentation",
    "NPI": "neural program induction",
    "MDI": "Micro-Dialect Identification",
    "AAVE": "African American Vernacular English",
    "SAE": "Standard American English",
    "DR": "Domain-Repair",
    "SPL": "Semantic Parser Localizer",
    "SANS": "Structure Aware Negative Sampling",
    "NMG": "Neural Mask Generator",
    "SREF": "Synset Relation-Enhanced Framework",
    "VCDM": "Variational Contextual Definition Modeler",
    "EA": "Entity alignment",
    "XEL": "Cross-lingual Entity Linking",
    "LEMM": "Article Element-aware Multi-representation Model",
    "HSCNN": "Hybrid-Siamese Convolutional Neural Network",
    "GAZP": "Zeroshot Executable Semantic Parsing",
    "PIIA": "parser-independent interactive approach",
    "SLSQL": "Schema-Linking SQL",
    "TACSA": "targeted aspect-category sentiment analysis",
    "DMSC": "Document-level Multi-aspect Sentiment Classification",
    "CoQA": "Conversational Question Answering",
    "ESD": "Erroneous Span Detection",
    "WiC": "Word-in-Context dataset",
    "IEN": "Interactive Entity Network",
    "RGAT": "relational graph attention networks",
    "MCTS": "Monte Carlo Tree Search",
    "NGDG": "Non-Guided Data Generation",
    "LMTC": "Large-scale Multi-label Text Classification",
    "LWANs": "Label-Wise Attention Networks",
    "PLTs": "Probabilistic Label Trees",
    "IF": "Interactive Fiction",
    "MPRC": "Multi-Passage Reading Comprehension",
    "DORB": "multi-armed bandit approach",
    "FQuAD": "French Question Answering Dataset",
    "GANs": "Generative Adversarial Networks",
    "WSC": "Winograd Schema Challenge",
    "CWA": "closed-world assumption",
    "OWA": "open-world assumption",
    "GNN": "graph neural network",
    "NwQM": "Neural wikipedia Quality Monitor",
    "SD": "Sustainable Development",
    "CRC": "Clinical Research Coordinators",
    "HOI": "higher-order inference",
    "OIE": "open information extraction",
    "KGPT": "knowledge-grounded pre-training",
    "CALM": "Contextual Action Language Model",
    "VLEP": "Video-and-Language Event Prediction",
    "HGN": "Hierarchical Graph Network",
    "ONUS": "One-to-N Unsupervised Sequence transduction",
    "TOWE": "Targeted opinion word extraction",
    "STN": "state-independent and time-evolving Network",
    "PADTG": "Partially-Aligned Data-to-Text Generation",
    "LABES": "LAtent BElief State",
    "VMSMO": "Multimodal Summarization with Multimodal Output",
    "DIMS": "Dual-Interaction-based Multimodal Summarizer",
    "CQE": "contextual query expansion",
    "SQuAD": "Stanford Question Answering Dataset",
    "NQ": "Natural Questions",
    "LIT": "Language Interpretability Tool",
    "UMLS": "unified medical language system",
    "RoFT": "Real or Fake Text",
    "OBS": "Oracle bone script",
    "IsOBS": "information system for OBS",
    "ADS": "adult-directed speech",
    "CDS": "child-directed speech",
    "Coach": "Coarse-to-fine approach",
    "KIC": "knowledge Copy",
    "NRG": "Neural Response Generators",
    "IRN": "Iterative Rectification Network",
    "ERR": "slot error rate",
    "AR": "autoregressive",
    "TTS": "text to speech",
    "PLuGS": "Pivot-Language Generation Stabilization",
    "STs": "Syntactic Transformations",
    "HCVAE": "hierarchical conditional variational autoencoder",
    "TQG": "Traditional Question Generation",
    "SQG": "Sequential Question Generation",
    "PPVAE": "Pre-train and Plug-in Variational Auto-Encoder",
    "PMLM": "probabilistically masked language model",
    "BAT": "Bidirectional Adversarial Topic",
    "MSC": "MultiScale Collaborative",
    "GCAN": "Graph-aware Co-Attention Networks",
    "CDL": "Curriculum Dual Learning",
    "GCBiA": "Gated Convolutional Bidirectional Attention-based Model",
    "PARG": "paraphrase augmented response generation",
    "CbR": "Conversing by Reading",
    "ELBO": "evidence lower bound",
    "FAQ": "Frequently Asked Questions",
    "PCPR": "Pronunciation-attentive Contextualized Pun Recognition",
    "BALM": "bilingual attention language model",
    "FSR": "Frame-based Sentence Representation",
    "LUs": "lexical units",
    "Sparc": "sparse representation",
    "EMT": "Explicit Memory Tracker",
    "MWP": "math word problem",
    "DTCA": "Decision Tree-based Co-Attention model",
    "DTE": "Tree-based Evidence model",
    "CaSa": "design Co-attention Self-attention networks",
    "DMIN": "Dynamic Memory Induction Networks",
    "HiAGM": "hierarchy-aware global model",
    "MWF": "morphological well-formedness",
    "WCEP": "Wikipedia Current Events Portal",
    "DQfD": "Deep Q-learning from Demonstrations",
    "BARQA": "question answering framework",
    "TSP": "Traveling Salesman Problem",
    "DQG": "Deep Question Generation",
    "FOBIE": "Focused Open Biological Information Extraction",
    "SANs": "self-attention networks",
    "ELMo": "monolingual contextualized word embeddings",
    "CG": "conversational graph",
    "BPE": "Byte Pair Encoding",
    "KL": "Kullback Leibler divergence",
    "PPPLs": "PLLs and their associated pseudo-perplexities",
    "SSPT": "understanding. Span Selection PreTraining",
    "LKB": "Lexical Knowledge Bases",
    "SVO": "Subject-Verb-Object",
    "NRE": "Neural Relation Extraction",
    "APLN": "Pooling with Learnable Norms",
    "TL": "transfer learning",
    "SSANs": "selective SANs",
    "DPE": "Dynamic Programming Encoding",
    "LJP": "Legal Judgement Prediction",
    "JPG": "Job Posting Generation",
    "ICD": "Classification of Diseases",
    "MLC": "Multi-Label Classification",
    "HDR": "Hyperbolic Dynamic Routing",
    "MOOCs": "Massive Open Online Courses",
    "EMR": "Electronic Medical Record",
    "CAt": "Contrastive Attention",
    "SEKT": "Semantic-Emotion Knowledge Transferring",
    "PAOTE": "Aspect and Opinion Terms Extraction",
    "ORL": "Opinion role labeling",
    "PLBA": "proposition-level biaffine attention",
    "MNER": "Multimodal Named Entity Recognition",
    "TLM": "translation language modeling",
    "BiRRE": "Bidirectional Residual Relation Embeddings",
    "LPMNR": "Projection Model with Negative Regularization",
    "ASC": "Aspect Sentiment Classification",
    "CoGAN": "Cooperative Graph Attention Networks",
    "RACL": "Relation-Aware Collaborative Learning",
    "GFMN": "Generative feature matching network",
    "NQG": "neural question generation",
    "BHWR": "Bayesian Hierarchical Words Representation",
    "STM": "Self-Training method",
    "GAE": "graph autoencoder",
    "MFS": "Most Frequent Sense",
    "SKEP": "Sentiment Knowledge Enhanced Pre-training",
    "UD": "Universal Dependencies",
    "SUD": "Surface-Syntactic Universal Dependencies",
    "HRGs": "Hyperedge Replacement Grammars",
    "DAC": "Dialogue Act Classification",
    "ER": "emotion recognition",
    "CSS": "Computational Social Sciences",
    "XQuAD": "Cross-lingual Question Answering Dataset",
    "IOFSM": "In-andOut Frame Score Margin",
    "BBCE": "Balanced Binary Cross-Entropy",
    "LSL": "language-shaped learning",
    "RTE": "textual entailment",
    "SHG": "Stylistic Headline Generation",
    "PAID": "Pretraining-Agnostic Identically Distributed",
    "TBIP": "text-based ideal point model",
    "MVEC": "multi-view encoder-classifier",
    "UMT": "unsupervised machine translation",
    "AVSD": "Audio-Visual Scene-Aware Dialogues",
    "EKD": "Enrichment Knowledge Distillation",
    "DIM": "Document Influence Model",
    "PG": "paraphrase generation",
    "ECL": "embodied cognitive linguistics",
    "SAS": "Slot Information Sharing",
    "EDUs": "elementary discourse units",
    "PPI": "protein-protein interactions",
    "EMAR": "memory activation and reconsolidation",
    "LF": "low-frequency",
    "MIE": "Medical Information Extractor",
    "NMN": "Neighborhood Matching Network",
    "AOPE": "Aspect-Opinion Pair Extraction",
    "SDRN": "Synchronous Double-channel Recurrent Network",
    "ESM": "Entity Synchronization Mechanism",
    "RSM": "Relation Synchronization Mechanism",
    "NLVL": "natural language video localization",
    "QGH": "query-guided highlighting",
    "PTB": "Penn Treebank",
    "DRTS": "Discourse representation tree structure",
    "DT": "document translation",
    "QT": "query translation",
    "SDU": "self-dependency units",
    "MERET": "Meta-Reinforced Multi-Domain State Generator",
    "MAML": "model-agnostic meta-learning algorithm",
    "TRADE": "transferable dialogue state generator",
    "GN": "Graph Network",
    "RGCs": "region-grounded captions",
    "FoV": "field-of-view",
    "INLP": "Iterative Null-space Projection",
    "MFEP": "Morphological Family Expansion Prediction",
    "KGAT": "Kernel Graph Attention Network",
    "MRLs": "Morphologically-Rich Languages",
    "NMRL": "Neural Models for MRLs",
    "URE": "Unsupervised relation extraction",
    "ADA": "adversarial domain adaptation",
    "NLVR": "language for visual reasoning",
    "HAT": "Hardware-Aware Transformers",
    "MRT": "Minimum Risk Training",
    "VNMT": "Variational Neural Machine Translation",
    "PDP": "paradigm discovery problem",
    "AWE": "Automated Writing Evaluation",
    "CS": "Code-switching",
    "RAMS": "Roles Across Multiple Sentences",
    "HTM": "Hierarchical Topic modeling",
    "STAGE": "Spatio-Temporal Answerer with Grounded Evidence",
    "MI": "mutual information",
    "XSP": "cross-database semantic parsing",
    "UDS": "Universal Decompositional Semantics",
    "CVAEs": "conditional variational autoencoders",
    "GPT": "Generative Pre-training",
    "TCs": "Topical Components",
    "FEVER": "Fact Extraction and VERification",
    "NILE": "Inference over Label-specific Explanations",
    "QuASE": "question-answer driven sentence encoding",
    "UNLI": "Uncertain Natural Language Inference",
    "VAT": "Virtual adversarial training",
    "BR": "bitext retrieval",
    "ReQA": "retrieval question answering",
    "GUI": "graphic user interface",
    "GED": "grammatical error detection",
    "GUIs": "graphical user interfaces",
    "DCANM": "N-gram Matching mechanism",
    "SDIs": "supplement-drug interactions",
    "DDIs": "identifying drug-drug interactions",
    "HDAG": "Hierarchical Directed Acyclic Graph",
    "SCF": "subcategorization frame",
    "DP": "dynamic programming",
    "MRS": "Minimal Recursion Semantics",
    "SNoW": "Sparse Network of Winnow",
    "SL": "sign language",
    "SDR": "Sufficient Dimensionality Reduction",
    "LAU": "linear associative units",
    "RNNs": "recurrent neural networks",
    "LaVi": "current language and vision",
    "TPP": "Trans-Pacific Partnership",
    "SMN": "sequential matching network",
    "PSO": "power spectrum overlap",
    "RP": "relative phase",
    "HCNs": "Hybrid Code Networks",
    "REs": "referring expressions",
    "MML": "maximum marginal likelihood",
    "ASTs": "abstract syntax trees",
    "MD": "mention detection",
    "FOFE": "fixed-size ordinally forgetting encoding",
    "FFNN": "simple feedforward neural network",
    "EDL": "Discovery and Linking",
    "MCI": "Mild Cognitive Impairment",
    "CNE": "complex networks and enriched them with word embedding",
    "ONLG": "Opinionated Natural Language Generation",
    "GBS": "Grid Beam Search",
    "HTDN": "Human Trafficking Deep Network",
    "PAS": "predicate argument structure",
    "CANE": "Context-Aware Network Embedding",
    "NBT": "Neural Belief Tracking",
    "GA": "Gated-Attention",
    "WRL": "word representation learning",
    "PP": "prepositional phrase",
    "GP": "Gaussian Process",
    "MCD": "Monte-Carlo Dropout",
    "TS": "text simplification",
    "NTS": "neural text simplification",
    "ATS": "automatic text simplification",
    "JS": "Jensen-Shannon",
    "RST": "Rhetorical Structure Theory",
    "DSWE": "discourse-specific word embeddings",
    "PKBP": "Pocket Knowledge Base Population",
    "KBC": "Keyphrase boundary classification",
    "APTs": "Anchored Packed Trees",
    "BWS": "Best worst scaling",
    "NCM": "Noisy Channel Model",
    "CALL": "computer-assisted language learning",
    "ERM": "Explicit Representation Model",
    "IRM": "Implicit Representation Model",
    "CER": "character error rate",
    "SLM": "structured language model",
    "PPL": "parsing accuracy perplexity",
    "UBG": "unification-based grammar",
    "IBNLG": "instance-based natural language generation",
    "SPG": "sentence-plan-generator",
    "SPR": "sentence-plan-ranker",
    "LCSR": "Longest Common Subsequence Ratio",
    "PLCG": "probabilistic left-corner grammar",
    "MERT": "Minimum error rate training",
    "tDAGs": "tripartite directed acyclic graphs",
    "TK": "Tree Kernel",
    "SCFG": "Synchronous Context Free Grammars",
    "GRE": "generic relation extraction",
    "CW": "confidence-weighted",
    "iHMM": "infinite HMM",
    "RR": "Relational-Realizational",
    "HD": "Head-Driven",
    "SC": "semantic class",
    "VE": "Virtual evidence",
    "ccMix": "cross-collection mixture",
    "CQI": "queries by intent",
    "AZ": "Argumentative Zoning",
    "BTS": "Byte-to-Span",
    "SNLI": "Stanford Natural Language Inference",
    "SRH": "speech recognition hypotheses",
    "SOM": "Self-Organizing Map",
    "FLMs": "factored language models",
    "GPB": "generalized parallel backoff",
    "DBN": "Dynamic Bayesian Network",
    "PoS": "Part-of-Speech",
    "FP": "filled pauses",
    "TDT": "Detection and Tracking",
    "TI": "textual inference",
    "MERS": "entropy based rule selection",
    "IHMM": "indirect hidden Markov model",
    "BP": "belief propagation",
    "BOW": "bag of words",
    "SRI": "semantic role identification",
    "SRC": "semantic role classification",
    "LVCSR": "large vocabulary continuous speech recognition",
    "SE": "set expansion",
    "TAP": "Textual Analogy Parsing",
    "AF": "Adversarial Filtering",
    "AMA": "associative multichannel autoencoder",
    "RMFN": "Recurrent Multistage Fusion Network",
    "TGN": "Temporal GroundNet",
    "UMWE": "Unsupervised Multilingual Word Embeddings",
    "UBWEs": "Unsupervised Bilingual Word Embeddings",
    "SCWS": "Stanford Contextual Word Similarity",
    "BCWS": "Bilingual Contextual Word Similarity",
    "CPG": "contextual parameter generator",
    "MTNT": "Translation of Noisy Text",
    "NLRA": "neural latent relational analysis",
    "AEM": "Auto-Encoder Matching",
    "PMN": "prototype memory network",
    "SGNNs": "Self-Governing Neural Networks",
    "HS": "hierarchical structure",
    "LRLs": "low-resourced languages",
    "RNFs": "recurrent neural filters",
    "SPRL": "semantic proto-role labeling",
    "CDMM": "Conversational Decision Making Model",
    "FiLM": "Feature-wise Linear Modulation",
    "DMN": "dynamic memory network",
    "WFSAs": "weighted finite state automata",
    "JMEE": "Jointly Multiple Events Extraction",
    "biLMs": "bidirectional language models",
    "CIN": "Convolutional Interaction Network",
    "SSP": "Shallow Semantic Parsing",
    "ERGM": "Exponential Random Graph Model",
    "PHSIC": "pointwise HSIC",
    "BBC": "British Broadcasting Corporation",
    "DRMM": "Deep Relevance Matching Model",
    "DPL": "deep probabilistic logic",
    "OIN": "Open-Domain Information Narration",
    "BiRNN": "bidirectional recurrent neural networks",
    "SDN": "Subgoal Discovery Network",
    "XLU": "cross-lingual language understanding",
    "WECA": "WordNet-Encoded Collocation-Attention network model",
    "ICON": "Interactive COnversational memory Network",
    "NPA": "negative phrase augmentation",
    "vSRL": "visual semantic role labeling",
    "IRFs": "impulse response functions",
    "GCCA": "generalized canonical correlation analysis",
    "IME": "input method engine",
    "SACT": "Self-Adaptive Control of Temperature",
    "CLMs": "corpus-agnostic Character-level Language Models",
    "ANN": "artificial neural network",
    "HSMM": "hidden semi-markov model",
    "HRS": "hierarchical relation structure",
    "MKBE": "multimodal knowledge base embeddings",
    "MGAN": "multi-grained attention network",
    "NCE": "Noise Contrastive Estimation",
    "PSAN": "Phrase-level Self-Attention Networks",
    "PPDB": "Paraphrase Database",
    "DDQ": "Deep Dyna-Q",
    "OpAtt": "cOperation-guided Attention-based sequence-to-sequence network",
    "AQG": "automatic question generation",
    "ITS": "Iterative Text Summarization",
    "MSMO": "multimodal output",
    "MMAE": "multimodal automatic evaluation",
    "ATR": "twin-gated recurrent network",
    "NYT": "New York Times",
    "SRU": "Simple Recurrent Unit",
    "CSRAN": "Co-Stack Residual Affinity Networks",
    "vMF": "von Mises-Fisher",
    "WMD": "Word Mover Distance",
    "WME": "Word Mover Embedding",
    "ACNN": "auto-correlational neural network",
    "PRU": "Pyramidal Recurrent Unit",
    "SDLM": "Sememe-Driven Language Model",
    "BTM": "Biterm Topic Model",
    "NNLM": "neural network language models",
    "TSA": "Targeted sentiment analysis",
    "WRAE": "word relation autoencoder",
    "WSI": "Word Sense Induction",
    "SLMs": "segmental language models",
    "FSTs": "finite state transducers",
    "BQ": "Bank Question",
    "SSEI": "sentence semantic equivalence identification",
    "MRs": "meaning representations",
    "ARC": "AI2 Reasoning Challenge",
    "WEAT": "word embedding association tests",
    "DTM": "direct translation model",
    "SRM": "Relevance Models",
    "NSDL": "National Science Digital Library",
    "MDP": "Markov Decision Processes",
    "SVD": "singular value decomposition",
    "ILR": "Interagency Language Roundtable",
    "SSNR": "soundbite speaker name recognition",
    "JMLLM": "joint morphological-lexical language model",
    "MLNs": "Markov Logic Networks",
    "ELLs": "English language learners",
    "SLT": "spoken language translation",
    "HIS": "Hidden Information State",
    "NART": "Non-autoregressive neural machine translation",
    "MPE": "multilingual pretrained encoder",
    "CAAT": "Cross Attention Augmented Transducer",
    "NCT": "Neural Chat Translation",
    "SumFC": "assessment framework for Summarization models",
    "UKE": "unsupervised keyphrase extraction",
    "MLRN": "Multi-Layer Revision Network",
    "CMIL": "Confidence-based Multi-Instance Learning",
    "LERGV": "Retrieval and Graph-based Verification network",
    "CAD": "counterfactually augmented data",
    "CDCR": "Cross-document event coreference resolution",
    "CKA": "centered kernel alignment",
    "AdS": "Adversarial Scrubber",
    "CT": "clinical trial",
    "TDA": "Topological Data Analysis",
    "SBS": "stochastic beam search",
    "CEFR": "European Framework of Reference",
    "QAC": "Query auto completion",
    "SFEM": "syntactic frame extension model",
    "UHD": "ultra-high dimensional",
    "SCST": "Self-Critical Sequence Training",
    "SPD": "Speaker Persona Detection",
    "PMPC": "Persona Match on Persona-Chat",
    "AMT": "Amazon Mechanical Turk",
    "QNLI": "question-answer entailment",
    "GFST": "gender-filtered self-training",
    "CRS": "Conversational Recommender Systems",
    "ToD": "task-oriented dialog",
    "HE": "Homomorphic encryption",
    "GC": "garbled circuit",
    "GRU": "gated recurrent unit",
    "PTM": "pre-trained models",
    "VQAG": "visual question-answer generation",
    "VGSI": "the Visual Goal-Step Inference",
    "gSCAN": "grounded SCAN",
    "CoLV": "collaborative latent variable",
    "KPN": "Knowledge Preservation Networks",
    "CSRL": "Conversational semantic role labeling",
    "EARL": "Entity-Agnostic Representation Learning",
    "MGE": "matching-guided embedding",
    "IDRR": "Implicit discourse relation recognition",
    "LMGC": "language model-based generative classifier",
    "SPT": "Sparse Phased Transformer",
    "HMTC": "Hierarchical multi-label text classification",
    "ZP": "zero pronoun",
    "IGND": "Iterative Graph Network-based Decoder",
    "MuVER": "Multi-View Entity Representations",
    "ULGN": "Uncertain Local-to-Global Network",
    "ZFET": "zero-shot fine-grained entity typing",
    "MSF": "multi-source fusion model",
    "LRE": "Low-resource Relation Extraction",
    "VRDs": "from visually rich documents",
    "SEU": "entity alignment method",
    "PCA": "principal component analysis",
    "CAPT": "ContrAstive Pre-Training",
    "LLE": "Lifelong Explanation",
    "CPMI": "mutual information between words",
    "RNNGs": "Recurrent Neural Network Grammars",
    "DIET": "Positional Attention for Transformers",
    "RPE": "Relative position embedding",
    "LFHC": "Low-level Fine-grained High-level Coarse-grained",
    "GCDF": "Gaussian Cumulative Distribution Function",
    "AMP": "Adversarial Mixing Policy",
    "SLATE": "Action policy for Textual Environments",
    "HRKD": "hierarchical relational knowledge distillation",
    "MISO": "Semantically Oversampling framework",
    "RAN": "Recurrent AtteNtion",
    "RHE": "redundant head enlivening",
    "SEA": "syntax-enhanced attention",
    "BiT": "bidirectional training",
    "SHAPE": "shifted absolute position embedding",
    "RPKHS": "Pre-trained Knowledge and Hierarchical Structure",
    "SEC": "Spelling Error Correction",
    "SSCL": "Self-Supervised Curriculum Learning",
    "BCN": "Biomedical Concept Normalization",
    "BCNH": "Concept Normalizer with Hypernyms",
    "STRM": "Segmented Token Recovery Mechanism",
    "CMR": "Conversational machine reading",
    "FOL": "first-order logic",
    "ZAR": "zero anaphora resolution",
    "PCR": "pronoun coreference resolution",
    "COIN": "a context-aware interaction network",
    "VDA": "Virtual Data Augmentation",
    "CATE": "ContrAstive pre-Trained modEl",
    "FL": "federated learning",
    "COQE": "Comparative Opinion Quintuple Extraction",
    "RaNet": "Relation aware Network",
    "MAS": "Multimodal abstractive summarization",
    "GPLMs": "generative pre-trained language models",
    "VG": "vision guided",
    "EHR": "electronic health records",
    "SgSum": "Sub-graph Selection Multi-document Summarization",
    "CWQ": "Complex Web Question",
    "CPL": "complementary policy learning",
    "TOD": "task oriented dialogs",
    "VAD": "arousal and dominance",
    "ALSA": "aspect-level sentiment analysis",
    "MATE": "multi-modal ATE",
    "MALSA": "multi-modal aspect-level sentiment analysis",
    "CSDS": "Customer Service Dialogue Summarization",
    "MoP": "Mixture of Partitions",
    "CDA": "counterfactual data augmentation",
    "CTG": "controllable text generation",
    "LABAN": "Label-Aware BERT Attention Network",
    "MRF": "Markov Random Fields",
    "SCR": "Signed Coreference Resolution",
    "PET": "Pattern Exploiting Training",
    "CSKB": "Commonsense knowledge bases",
    "QQP": "Quora Question Pair",
    "REE": "role-filler entity extraction",
    "FET": "Fine-grained Entity Typing",
    "MVA": "multi-vector attention",
    "CFL": "continual few-shot learning",
    "UPOS": "Universal POS tags",
    "IGA": "Intent-Guided Assistant",
    "ASAG": "Automatic short answer grading",
    "SFRN": "Feature-wise transformation Relation Network",
    "CII": "Content Informed Index",
    "ATSC": "aspect target sentiment classification",
    "AKD": "Adaptive Knowledge Distillation",
    "MARQ": "Multimodal ARgument Quality assessor",
    "NDH": "Dialogue History",
    "CVDN": "Cooperative Vision-and-Dialogue Navigation",
    "ReLA": "Rectified Linear Attention",
    "SALT": "Stackelberg Adversarial Regularization",
    "SCUs": "Summary Content Units",
    "STUs": "Semantic Triplet Units",
    "EVI": "Evidential Uncertainty",
    "iMRC": "Interactive machine reading comprehension",
    "DIL": "domain incremental learning",
    "CONAN": "continous patterns",
    "LIiC": "lexical inference in context",
    "EU": "European Union",
    "CFD": "counterfactual detection",
    "STEL": "similarity-based STyle EvaLuation framework",
    "KSTER": "Kernel-Smoothed Translation with Example Retrieval",
    "FPs": "Fermi Problems",
    "BIFI": "Break-It-Fix-It",
    "CAPE": "Context-Aware Private Embeddings",
    "FSED": "few-shot event detection",
    "MoPQ": "Matching-oriented Product Quantization",
    "MCL": "Multinoulli Contrastive Loss",
    "BTR": "Bayesian Topic Regression",
    "TKG": "Temporal knowledge graph",
    "ODEs": "neural ordinary differential equations",
    "FAME": "feature-based adversarial meta-embeddings",
    "CoR": "evaluating coreference resolution",
    "MLLMs": "multilingual language models",
    "MSR": "Multi-Sentence Resampling",
    "CBART": "Constrained BART",
    "PL": "Programming Languages",
    "COE": "Context-Oriented Embedding",
    "TAA": "Text AutoAugment",
    "UCRN": "Crossmodal Refinement Network",
    "MMIM": "framework named MultiModal InfoMax",
    "ABSC": "Graph-based Aspect-based Sentiment Classification",
    "ASQP": "Aspect Sentiment Quad Prediction",
    "TSLV": "sentence localization in videos",
    "APGN": "Adaptive Proposal Generation Network",
    "RRM": "representation reconstruction module",
    "ICM": "independent causal mechanisms",
    "CAQA": "domain adaptation for QA",
    "CBR": "case-based reasoning",
    "FN": "false negative",
    "CFIE": "counterfactual IE",
    "MHCH": "Machine-Human Chatting Handoff",
    "RSSN": "Role-Selected Sharing Network",
    "WSTL": "Wasserstein Selective Transfer Learning",
    "SWEAT": "Sliced Word Embedding Association Test",
    "CH": "Computational Humour",
    "QWK": "Quadratic Weighted Kappa",
    "IG": "Integrated Gradients",
    "DIG": "Discretized Integrated Gradients",
    "IBIS": "inference by iterative shuffling",
    "MaRVL": "Reasoning over Vision and Language",
    "WS": "Winograd Schema",
    "TAO": "tree alternating optimization",
    "SCDL": "Self-Collaborative Denoising Learning",
    "PMR": "Perfect Match Ratio",
    "TCAG": "Causal Analysis Graph",
    "SCP": "Semantic Context Path",
    "UMR": "Uniform Meaning Representations",
    "MND": "multiple narrative disentanglement",
    "FSD": "First story detection",
    "SIP": "Session Initiation Protocol",
    "ODPs": "overt displays of power",
    "SCTM": "Shared Components Topic Model",
    "SCMs": "segment choice models",
    "PHI": "personal health information",
    "TCNL": "Calculus for Natural Language",
    "TEA": "Temporal Expression Anchoror",
    "TMI": "Merging for Indexing",
    "LCTLs": "Less Commonly Taught Languages",
    "EBMT": "Example Based Machine Translation",
    "SW": "semantic web",
    "XR": "expectation regularization",
    "MSN": "multi-hop selector network",
    "MoEL": "Mixture of Empathetic Listeners",
    "KET": "Knowledge-Enriched Transformer",
    "CAMIL": "extensible Context-Assisted Multiple Instance Learning",
    "CCMM": "Context Clue Matching Mechanism",
    "RSNs": "Relational Siamese Networks",
    "WL": "weakly labeled",
    "DCA": "Dynamic Context Augmentation",
    "ESE": "Entity Set Expansion",
    "TLNN": "Lattice Neural Net- work",
    "RPs": "relation phrases",
    "CaRe": "Canonicalization-infused Representations",
    "DSRE": "Distantly Supervised Relation Extraction",
    "LSAN": "Label-Specific Attention Network",
    "HAPN": "hierarchical attention prototypical networks",
    "MLMA": "deep semantic Alignment",
    "CAIS": "collected corpus",
    "SAC": "auxiliary classifier",
    "rnng": "Recurrent Neural Network Grammar",
    "ECIM": "Event-Centric Indicator Measure",
    "gCAS": "gated Continue-Act-Slots",
    "TCN": "Convolutional Neural Networks",
    "WSLLN": "weakly supervised language localization networks",
    "DIORA": "deep inside-outside recursive autoencoders",
    "SCUD": "Spoken Conversation Universal Dependencies",
    "TOP": "Task Oriented Parse",
    "SVCCA": "Singular Value Canonical Correlation Analysis",
    "CLMRC": "Cross-Lingual Machine Reading Comprehension",
    "MTMSN": "Multi-Type Multi-Span Network",
    "DQD": "Duplicate Question Detection",
    "HRG": "hierarchical response generation",
    "IMN": "interactive matching network",
    "SSVN": "Semi-Supervised Stable Variational Network",
    "WAEs": "Wasserstein autoencoders",
    "HOCA": "High-Order Cross-Modal Attention",
    "DAN": "Dual Attention Networks",
    "ASGN": "Adaptive Semantic Guidance Network",
    "TGCM": "topic-guided coherence modeling",
    "RNNG": "Recurrent Neural Network grammar",
    "ADR": "adverse drug reaction",
    "XNLI": "cross-lingual natural language inference",
    "XQA": "cross-lingual question answering",
    "KEAG": "Knowledge-Enriched Answer Generator",
    "MC": "machine comprehension",
    "pSQL": "Pseudo-SQL",
    "ADIN": "asynchronous deep interaction network",
    "VIB": "variational information bottleneck",
    "DAGs": "directed acyclic graphs",
    "QAit": "Answering with Interactive Text",
    "ASN": "Attribute-aware Sequence Network",
    "NCLS": "Neural Cross-Lingual Summarization",
    "ARL": "Auto-tuned Reinforcement Learning",
    "IMaT": "Iterative Matching and Translation",
    "PHVM": "Planning-based Hierarchical Variational Model",
    "GST": "Generative Style Transformer",
    "BDI": "bilingual dictionary induction",
    "SST": "Stanford Sentiment Treebank",
    "HME": "Hierarchical Meta-Embeddings",
    "MPPA": "Multi Pairwise Procrustes Analysis",
    "SBNN": "search-based neural network",
    "TEES": "Turku Event Extraction System",
    "PESG": "Editing based Summary Generator",
    "GSP": "Spanning based Parsing",
    "BLEU": "bilingual evaluation understudy",
    "LVM": "latent variable models",
    "IBP": "Interval Bound Propagation",
    "MetaR": "Meta Relational Learning",
    "DRO": "distributionally robust optimization",
    "PIE": "Parallel Iterative Edit",
    "ARAML": "Adversarial Reward Augmented Maximum Likelihood",
    "WVM": "vector representation model",
    "WOz": "Wizard of Oz",
    "GECOR": "Ellipsis and CO-reference Resolution model",
    "HMNs": "Heterogeneous Memory Networks",
    "SAL": "Selective Adversarial Learning",
    "CAN": "constrained attention networks",
    "HGAT": "Heterogeneous Graph ATtention networks",
    "DISP": "discriminate perturbations",
    "CCP": "Citation count prediction",
    "FPDG": "Fidelity-oriented Product Description Generator",
    "ELSTM": "Entity-label-guided Long Short-Term Memory",
    "HMGCN": "Hierarchical Multi Graph Convolutional Network",
    "DEBUG": "DEnse Bottom-Up Grounding",
    "IPDG": "Inner Product Delaunay Graph",
    "NPD": "Neural Personal Discrimination",
    "DASC": "Document-level Aspect Sentiment Classification",
    "SCARN": "Sequential Convolutional Attentive Recurrent Network",
    "CDT": "dependency tree",
    "ART": "AutoRegressive Translation",
    "CLBT": "Cross-Lingual BERT Transformation",
    "HMEAE": "Hierarchical Modular Event Argument Extraction",
    "RSA": "Representational Similarity Analysis",
    "CTM": "Consistency Teacher Module",
    "SQA": "Scenario-based question answering",
    "DROP": "Discrete Reasoning Over Passages",
    "IL": "imitation learning",
    "DSR": "distributional semantics reward",
    "VFGE": "Variation Family-enhanced Graph Embedding",
    "VA": "Vossian Antonomasia",
    "EUs": "elementary units",
    "MAMS": "Multi-Aspect Multi-Sentiment",
    "DENS": "Emotions of Narrative Sequences",
    "CPTP": "charge-based prison term prediction",
    "DGN": "Deep Gating Network",
    "NRMS": "multi-head self-attention",
    "RUN": "Realistic Urban Navigation",
    "CATD": "novel Context-Aware Thread Detection",
    "KGIS": "Knowledge Graph Induction Service",
    "LMA": "language model adaptation",
    "SS": "Sentence Simplification",
    "CA": "Classical Arabic",
    "UER": "Universal Encoder Representations",
    "EC": "eigen character",
    "WFSTs": "Weighted Finite State Transducers",
    "TERp": "TER-plus",
    "ciQA": "complex interactive Question Answering",
    "PDF": "probability density function",
    "SIDE": "Summarization Integrated Development Environment",
    "OLCTS": "Language and Culture Training System",
    "HARD": "Accuracy Retrieval from Documents",
    "MUG": "Unification Grammar",
    "MSLM": "multi-speaker language model",
    "BPs": "base phrases",
    "CBA": "cognition based attention",
    "LDST": "location-based dynamic sentiment-topic model",
    "MLP": "Multi-Layer Perceptron",
    "SVR": "Support Vector Regression",
    "SCDV": "Sparse Composite Document Vector",
    "SWS": "single-grained WS",
    "MWS": "multi-grained WS",
    "SEST": "syntactic trees",
    "TKs": "Tree Kernels",
    "QRPE": "Relevance Prediction and Explanation",
    "GNR": "Globally Normalized Reader",
    "MMS": "Multi-modal Summarization",
    "QLM": "Quantum Language Model",
    "ALA": "automated lyric annotation",
    "DRGN": "deep recurrent generative decoder",
    "TQs": "tag questions",
    "SF": "Slot Filling",
    "NITE": "Neural Inductive TEaching framework",
    "DLATK": "Differential Language Analysis Toolkit",
    "ANNs": "Artificial neural networks",
    "MANN": "Memory Augmented Neural Networks",
    "MCTAG": "multicomponent TAG formalisms",
    "SOV": "subject-object-verb",
    "GMLM": "Gaussian-Mixture Language Model",
    "TMLM": "Tied-Mixture Language Model",
    "FSTTM": "Finite-State Turn-Taking Machine",
    "SDA": "spherical discriminant analysis",
    "DBNs": "Dynamic Bayesian Networks",
    "LUM": "language understanding model",
    "HFDS": "high-frequency domain-specific",
    "MPFE": "minimum phone frame error",
    "RBMT": "rule-based machine translation",
    "STD": "spoken term detection",
    "TST": "term specific thresholding",
    "STAT": "Speech Transcription Analysis Tool",
    "HUME": "Human UCCA-based MT Evaluation",
    "LML": "Lifelong machine learning",
    "RBF": "radial-basis function",
    "SmBoP": "Semi-autoregressive Bottom-up Parser",
    "MVR": "Multi-view Subword Regularization",
    "QReCC": "Question Rewriting in Conversational Context",
    "PMI": "pointwise mutual information",
    "ITR": "Image-text retrieval",
    "MTAG": "Modal-Temporal Attention Graph",
    "RLHR": "Reinforced Label Hierarchy Reasoning",
    "TTL": "test-time learning",
    "EVR": "multi-hop Verbal Reasoner",
    "GPS": "General Problem Solver",
    "MPPIs": "Minimal Prediction Preserving Inputs",
    "MCRC": "multiple-choice reading comprehension",
    "CFCS": "correctness of textual summarization",
    "CGR": "Contextual Gazetteer Representation",
    "NUP": "next-utterance prediction",
    "PAG": "paragraph association graph",
    "CR": "coreference resolution",
    "SAN": "Self-Attention Network",
    "FFN": "Feed-Forward Network",
    "MANs": "Mask Attention Networks",
    "DMAN": "dynamic mask attention network",
    "OM": "opinion mining",
    "TSMSA": "sequence labeling with Multi-head Self-Attention",
    "CWR": "contextual word representations",
    "SeqKD": "sequence-level knowledge distillation",
    "FVSQA": "Fact-based Visual Spoken-Question Answering",
    "GCI": "Graph-based Causal Inference",
    "CMGE": "graph supporting facts extraction",
    "MCRF": "Masked Conditional Random Field",
    "GenQA": "generative question answering",
    "ECtHR": "European Court of Human Rights",
    "VRL": "Variational Representation Learning",
    "WEC": "Wikipedia Event Coreference",
    "KILT": "knowledge-intensive language tasks",
    "TF": "term frequencies",
    "MuSE": "Multimodal Stressed Emotion",
    "NTM": "Neural Topic Models",
    "SETH": "Strong Exponential Time Hypothesis",
    "ABCD": "Action-Based Conversations Dataset",
    "LOGER": "logic reasoning for explainable recommendation",
    "SOrT": "Sub-question Oriented Tuning",
    "SSI": "semi-supervised initialization",
    "HLG": "HeadLine Grouping",
    "LNSR": "Layer-wise Noise Stability Regularization",
    "NF": "normalizing flows",
    "NDCG": "normalized discounted cumulative gain",
    "LCPO": "loop-clipping policy optimisation",
    "DECI": "document-level ECI",
    "FUDGE": "Future Discriminators for Generation",
    "ARAE": "adversarially regularized autoencoder",
    "IRB": "Institutional Review Board",
    "UBM": "upstream bias mitigation",
    "GMASK": "Group Mask",
    "MHT": "Multi-Hop Transformer",
    "VGAE": "variational graph-auto-encoder",
    "MEL": "medical entity linking",
    "TSLM": "Time-Stamped Language Model",
    "CC": "classifier chain",
    "GSum": "guided summarization framework",
    "AAs": "Artificial Annotators",
    "ENG": "Entity-based Narrative Graph",
    "LFQA": "long-form question answering",
    "KPG": "keyphrase generation",
    "NPLM": "neural probabilistic language model",
    "LLPs": "latent language policies",
    "ANT": "adversarial neural transfer",
    "SCCL": "Clustering with Contrastive Learning",
    "TITA": "Topic-Aware text matching model",
    "LN": "lexical normalization",
    "UGT": "user-generated text",
    "CGNet": "Concept Generation Network",
    "RUQ": "Relative Utterance Quantity",
    "SKG": "Static knowledge graph",
    "SKGE": "Static knowledge graph embedding",
    "TKGE": "knowledge graph (TKG) embedding",
    "RTFE": "Recursive Temporal Fact Embedding",
    "SGG": "Select-Guide-Generate",
    "DAM": "Dyadic Attention Mechanism",
    "TAC": "TA classification",
    "TSRT": "similarity with round-trip translation",
    "DAGN": "discourse-aware graph network",
    "RG": "Robustness Gym",
    "NEL": "neural entity linking",
    "EVAs": "enterprise virtual agents",
    "TN": "Text Normalization",
    "PFA": "Pretrain-Finetuning Approach",
    "FCM": "Compositional Embedding Model",
    "TBCNN": "tree-based convolutional neural network",
    "SSRs": "semantic sequential representations",
    "NIH": "Institutes of Health",
    "ETTS": "Evolutionary Trans-Temporal Summarization",
    "NCs": "noun compounds",
    "MiCR": "micro collaborative ranking",
    "MaCR": "macro collaborative ranking",
    "MWUs": "multi-word units",
    "NLP": "Natural Language Processing",
    "MELM": "maximum entropy language models",
    "CI": "Chart Inference",
    "IPS": "Interactive Personalized Summarization",
    "PRO": "pairwise ranking optimization",
    "FSA": "finite-state automata",
    "PDA": "pushdown automata",
    "MVM": "Multi-View Mixture",
    "WTM": "word trigger method",
    "CDHMM": "crouching Dirichlet, hidden Markov model",
    "OPCA": "Oriented Principal Component Analysis",
    "CPLSA": "Coupled Probabilistic Latent Semantic Analysis",
    "LCSeg": "Lexical Chain Segmenter",
    "CNF": "Chomsky Normal Form",
    "LNF": "Lexical Normal Form",
    "PT": "phrase table",
    "REQ": "Recurrent event queries",
    "AN": "adjective-noun composition",
    "IPA": "international phonetic alphabet",
    "AQL": "Annotation Query Language",
    "MEM": "Multi-Experts Model",
    "ASRL": "Summarization using Reinforcement Learning",
    "FDT": "forced derivation tree",
    "pFSM": "probabilistic finite state machine",
    "ERPs": "event-related potentials",
    "CAI": "computer-assisted interpreting",
    "TGVAE": "topic-guided variational auto-encoder",
    "GMM": "Gaussian mixture model",
    "NFSTs": "neural finite state transducers",
    "WAE": "Wasserstein Autoencoder",
    "RNF": "Riemannian Normalizing Flow",
    "KBSQA": "knowledge graph based simple question answering",
    "VLAWE": "Vector of Locally-Aggregated Word Embeddings",
    "HiGRU": "hierarchical Gated Recurrent Unit",
    "BWE": "Bilingual Word Embeddings",
    "ReWE": "regressing word embeddings",
    "BiRD": "fine-grained, bigram relatedness dataset",
    "DSSM": "Deep Structured Semantic Models",
    "TMKGE": "modeling with knowledge graph embedding",
    "CWI": "Complex Word Identification",
    "GRank": "graph pattern entity ranking Model",
    "RMSE": "root mean square error",
    "KALM": "Knowledge-Augmented Language Model",
    "SAWRs": "syntax-aware word representations",
    "BoSs": "Bag-of-Sequences",
    "MTSA": "Multi-mask Tensorized Self-Attention\u201d",
    "JMAN": "Joint Multi-label Attention Network",
    "HAN": "Hierarchical Attention Network",
    "CVEs": "Common Vulnerabilities and Exposures",
    "NVD": "National Vulnerability Database",
    "VLAE": "Locally Aggregated Embeddings",
    "OLID": "Offensive Language Identification Dataset",
    "CNs": "Consensus Networks",
    "BoSE": "Bag of Sub-Emotions",
    "PGR": "Phenotype-Gene Relations",
    "VQD": "Visual Query Detection",
    "PNE": "Personalized Neural Embedding",
    "BIDAF": "Bi-Directional Attention Flow",
    "RRC": "Review Reading Comprehension",
    "SVA": "subject-verb agreement",
    "OTEs": "opinion target expressions",
    "ACAN": "adversarial category alignment network",
    "MMN": "multi-level memory networks",
    "AMFE": "Adversarial Multi-modal Feature Encoding",
    "WTQ": "Wiki Table Questions",
    "AHE": "Heterogeneous Embeddings",
    "XML": "Extreme Multi-label classification",
    "CLSC": "Compact Latent Space Clustering",
    "KBE": "knowledge base Embeddings",
    "RNNLM": "Recurrent neural network language models",
    "AMN": "associated memory network",
    "PASA": "predicate argument structure analysis",
    "ENASA": "event-noun argument structure analysis",
    "VVD": "variational vocabulary dropout",
    "RRNs": "introduce Recursive Routing Networks",
    "RCT": "randomized controlled trials",
    "SwDA": "Switchboard Dialogue Act",
    "IPDAs": "intelligent personal digital assistants",
    "HRED": "Hierarchical Recurrent Encoder-Decoder",
    "SGU": "Scalar Gated Unit",
    "CNM": "network for matching",
    "IM": "instant-messaging",
    "DBT": "dialog-based tutoring system",
    "IBE": "Infobox Extraction",
    "ETIP": "Tagging on Insurance Policy",
    "UAD": "Unsupervised Abbreviation Disambiguation",
    "NATS": "Neural abstractive text summarization",
    "FETC": "Fine-grained Entity Type Classification",
    "WEAN": "Word Embedding Attention Network",
    "MIR": "mathematical information retrieval",
    "DMR": "Dirichlet Multinomial Regression",
    "dDMR": "deep Dirichlet Multinomial Regression",
    "DIVE": "distributional inclusion vector embedding",
    "NTNs": "neural tensor networks",
    "RNTNs": "recursive neural tensor networks",
    "BLSTM": "Bi-directional Long Short Term Memory",
    "ELS": "entity linking system",
    "SGTB": "structured gradient tree boosting",
    "BiBSG": "Beam Search with Gold path",
    "PETE": "Evaluation using Textual Entailments",
    "MulR": "Multi-Resolution Representation",
    "MAN": "multinomial adversarial network",
    "MDTC": "multi-domain text classification",
    "NNs": "Neural Networks",
    "PBLM": "Pivot Based Language Model",
    "TPRs": "Tensor Product Representations",
    "TPGN": "Tensor Product Generation Network",
    "CARNN": "Context-dependent Additive Recurrent Neural Network",
    "GDAN": "Generative Domain-Adaptive Nets",
    "LTMF": "LSTM-Topic matrix factorization",
    "GBN": "Generative Bridging Network",
    "HiSAN": "higher-order syntactic attention network",
    "VHCR": "Variational Hierarchical Conversation RNNs",
    "SHCNN": "Siamese hierarchical convolutional neural network",
    "CISIR": "conversation identification by similarity ranking",
    "ELDEN": "Linking using Densified Knowledge Graphs",
    "SCPNs": "syntactically controlled paraphrase networks",
    "SWAF": "Stacking With Auxiliary Features",
    "biLM": "bidirectional language model",
    "KIGN": "Key Information Guide Network",
    "RLMs": "reference-less measures",
    "SPENs": "structured prediction energy networks",
    "DSG": "directional skip-gram",
    "QAMRs": "Question-Answer Meaning Representations",
    "pBE": "pruned Basic Elements",
    "HACA": "hierarchically aligned cross-modal attention",
    "RF": "Random Forest",
    "MTQE": "Machine Translation Quality Estimation",
    "SNs": "Siamese Networks",
    "BoE": "Bag of Experts",
    "AMRL": "Alexa meaning representation language",
    "NLPf": "NLP Lean Programming framework",
    "SLs": "sentiment lexicons",
    "OE": "Order Embeddings",
    "GMB": "Groningen Meaning Bank",
    "SWEMs": "Simple Word-Embedding-based Models",
    "GCL": "Global Context Layer",
    "TDS": "Text Deconvolution Saliency",
    "AI": "Artificial Intelligence",
    "SEAs": "semantically equivalent adversaries",
    "SEARs": "semantically equivalent adversarial rules",
    "AREL": "Adversarial REward Learning",
    "PCCA": "Partial Canonical Correlation Analysis",
    "DPCCA": "Deep Partial Canonical Correlation Analysis",
    "MNs": "Memory networks",
    "TMNs": "target-sensitive memory networks",
    "RNs": "reasoning. Relation Networks",
    "DDs": "diagnosis descriptions",
    "CDs": "code descriptions",
    "TDNN": "two-stage deep neural network",
    "STAG": "synchronous tree-adjoining grammar",
    "LVeGs": "Latent Vector Grammars",
    "LMMs": "Latent Meaning Models",
    "IAA": "inter-annotator agreements",
    "EED": "Exemplar Encoder-Decoder network",
    "AAE": "African-American English",
    "GLAD": "Dialogue State Tracker",
    "NKD": "neural knowledge diffusion",
    "CM": "Code-mixed",
    "NPNs": "Nugget Proposal Networks",
    "RSI": "Relation Schema Induction",
    "HRSI": "Higher-order Relation Schema Induction",
    "TFBA": "Back-off and Aggregation",
    "RAML": "reward augmented maximum likelihood",
    "QCN": "Question Condensing Networks",
    "ADL": "Architecture Definition Language",
    "MNED": "Multimodal Named Entity Disambiguation",
    "NASH": "Architecture for Semantic Hashing",
    "DFG": "Dynamic Fusion Graph",
    "CCMs": "constrained conditional models",
    "DRNN": "disconnected recurrent neural network",
    "NSTC": "Neural Sparse Topical Coding",
    "STC": "Sparse Topical Coding",
    "EDRM": "Entity-Duet Neural Ranking Model",
    "BLSE": "Bilingual Sentiment Embeddings",
    "ATSA": "aspect-term sentiment analysis",
    "HCSC": "Hybrid Contextualized Sentiment Classifier",
    "CSAA": "Cold-Start Aware Attention",
    "MMID": "Massively Multilingual Image Dataset",
    "DSMN": "Dynamic Spatial Memory Network",
    "GPU": "graphics processing unit",
    "OONP": "Object-oriented Neural Programming",
    "RNTN": "Recurrent neural tensor networks",
    "MLN": "Markov Logic Network",
    "SCRFs": "semi-Markov conditional random fields",
    "TQA": "Textbook Question Answering",
    "NNER": "Neural Named Entity Recognition",
    "AAPR": "automatic academic paper rating",
    "CBOW": "continuous bag of words",
    "MEAN": "Multi-sentiment-resource Enhanced Attention Network",
    "POV": "point of view",
    "AML": "anti money laundering",
    "DCFEE": "Document-level Chinese Financial Event Extraction",
    "DGMs": "Deep generative models",
    "DRL": "deep reinforcement learning",
    "IoI": "interaction-over-interaction",
    "LTR": "learning to route",
    "BLISS": "Bilingual Lexicon Induction with Semi-Supervision",
    "MDRM": "multimodal deep regression model",
    "MELD": "Multimodal EmotionLines Dataset",
    "AFS": "Argument Facet Similarity",
    "DOER": "Dual crOss-sharEd RNN framework",
    "GWAP": "Game-With-A-Purpose",
    "GOLC": "method under length constraint",
    "PWWS": "probability weighted word saliency",
    "LDL": "label distribution learning",
    "UBWE": "Unsupervised bilingual word embedding",
    "SynST": "syntactically supervised Transformer",
    "MILk": "Monotonic Infinite Lookback",
    "ERNIE": "enhanced language representation model",
    "MuGNN": "Multi-channel Graph Neural Network model",
    "PDR": "Past Decode Regularization",
    "BPC": "bits-per-character",
    "RIPA": "relational inner product association",
    "ENAS": "Efficient Neural Architecture Search",
    "CAS": "continual architecture search",
    "FGST": "fine-grained text sentiment transfer",
    "SIVAE": "syntax-infused variational autoencoder",
    "BiSET": "Bi-directional Selective Encoding with Template",
    "KAR": "Knowledge Aided Reader",
    "QFE": "Query Focused Extractor",
    "PU": "positive-unlabeled",
    "DAML": "method based on meta-learning",
    "CMAC": "cross-model automatic commenting",
    "HDE": "Heterogeneous Document-Entity",
    "EPAr": "Explore-Propose-Assemble reader",
    "MLMAN": "multi-level matching and aggregation network",
    "LCC": "Local Coordinates Coding",
    "ENFR": "English-German (EN-DE) and English-French",
    "CLTL": "Cross-lingual transfer learning",
    "UBLI": "unsupervised bilingual lexicon induction",
    "DNPG": "Decomposable Neural Paraphrase Generator",
    "DAP": "domain-adaptive pre-training",
    "GRAD": "Generalized Resource-Adversarial Discriminator",
    "BPEs": "Byte Pair Encodings",
    "RBAN": "Reinforced Bidirectional Attention Network",
    "VTQA": "Textual Question Answering",
    "EmoDS": "emotional dialogue system",
    "IDS": "Incremental Dialogue System",
    "BCS": "Budget-Conscious Scheduling",
    "REAT": "Retrieval-Enhanced Adversarial Training",
    "VPN": "Vocabulary Pyramid Network",
    "StRE": "Self Attentive Revision Encoder",
    "HNN": "Hubless Nearest Neighbor",
    "AGR": "Generating compact-answer Representation",
    "TVQA": "Trivia and video QA",
    "NLSM": "Natural Language Sentence Matching",
    "NVLM": "neural variational language model",
    "HSP": "Hierarchical Semantic Parsing",
    "LBP": "loopy belief propagation",
    "RCN": "reason comparing network",
    "GLEN": "Generalized Lexical ENtailment model",
    "PTO": "Point-Then-Operate",
    "MMD": "multimodal dialogue dataset",
    "DLI": "dialogue logistic inference",
    "SUMBT": "slot-utterance matching belief tracker",
    "LOF": "local outlier factor",
    "CSRR": "Conversational Semantic Relationship RNN",
    "ATIS": "Air Travel Information Service",
    "VGDS": "Video-Grounded Dialogue Systems",
    "MTN": "Multimodal Transformer Networks",
    "EWISE": "Extended WSD Incorporating Sense Embeddings",
    "NLM": "Neural Language Modelling",
    "GPPL": "Gaussian process preference learning",
    "OOVs": "out-of-vocabulary words",
    "TRL": "Task Refinement Learning",
    "NNLG": "Neural natural language generation",
    "KGLM": "knowledge graph language model",
    "FA": "force attention",
    "ViST": "Visual Story Telling",
    "FSM": "Finite State Machine",
    "SSiD": "Scaffolding Structure in Decoder",
    "SSiL": "Scaffolding Structure in Loss",
    "CMRC": "Conversational machine reading comprehension",
    "BAFF": "Basic and Fairly Flawed",
    "HLTM": "Human-in-the-Loop Topic Modeling",
    "RAT": "Relevance-based Auxiliary Task",
    "ReDAN": "Recurrent Dual Attention Network",
    "MulT": "Multimodal Transformer",
    "BE": "Basic Elements",
    "FRC": "relation clustering algorithm",
    "RASCs": "raw semantic classes",
    "MIRA": "Margin Infused Relaxed Algorithm",
    "ASF": "aspect selection function",
    "fMRI": "functional Magnetic Resonance Imaging",
    "FS": "feature selection",
    "WFO": "frequency and odds",
    "CN": "confusion network",
    "RCG": "Range Concatenation Grammar",
    "WBMs": "word boundary markers",
    "SSG": "synthetic synchronous grammar",
    "STSSG": "synchronous tree sequence substitution grammar",
    "HMTM": "Hidden Markov Tree Models",
    "CD": "coordinate descent",
    "TED": "Tree Edit Distance",
    "ESSK": "Extended String Subsequence Kernel",
    "LMIR": "Model for Information Retrieval",
    "RTGs": "regular tree grammars",
    "ETL": "Guided Transformation Learning",
    "TBL": "Based Learning",
    "LW": "lexical weighting",
    "IRC": "Internet Relay Chat",
    "MTAL": "multi-task active learning",
    "ASTRL": "A Sentence Transformation Rule Learner",
    "VSD": "Verb Sense Disambiguation",
    "PRA": "Phrase Resolution Algorithm",
    "LARS": "Least Angle Regression",
    "DAs": "dialog acts",
    "LSTMs": "long short term memory"
}